{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "face_maskrcnn.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYEPuaUhweEG",
        "outputId": "dee5b869-8bb8-45f4-ef46-2b7d6a15ed17"
      },
      "source": [
        "%cd\n",
        "  \n",
        "!git clone https://github.com/assia855/Mask_RCNN.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root\n",
            "Cloning into 'Mask_RCNN'...\n",
            "remote: Enumerating objects: 962, done.\u001b[K\n",
            "remote: Total 962 (delta 0), reused 0 (delta 0), pack-reused 962\u001b[K\n",
            "Receiving objects: 100% (962/962), 125.23 MiB | 30.29 MiB/s, done.\n",
            "Resolving deltas: 100% (562/562), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-nU9Kwlwj1x",
        "outputId": "231e2c97-82b8-4b52-d3e0-b542011e6f00"
      },
      "source": [
        "%cd ~/Mask_RCNN \n",
        "\n",
        "!pip install -q  PyDrive \n",
        "!pip install -r requirements.txt\n",
        "!python setup.py install \n",
        "\n",
        "print(\"/Done\")\n",
        "import tensorflow as tf \n",
        "print(\"tensorflow version\",tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/Mask_RCNN\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (1.4.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (7.0.0)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (0.29.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (3.2.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 6)) (0.16.2)\n",
            "Collecting tensorflow-gpu==1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/ad/933140e74973fb917a194ab814785e7c23680ca5dee6d663a509fe9579b6/tensorflow_gpu-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (411.5MB)\n",
            "\u001b[K     |████████████████████████████████| 411.5MB 41kB/s \n",
            "\u001b[?25hCollecting keras==2.1.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ba/65/e4aff762b8696ec0626a6654b1e73b396fcc8b7cc6b98d78a1bc53b85b48/Keras-2.1.5-py2.py3-none-any.whl (334kB)\n",
            "\u001b[K     |████████████████████████████████| 337kB 39.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 9)) (4.1.2.30)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 10)) (2.10.0)\n",
            "Requirement already satisfied: imgaug in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 11)) (0.2.9)\n",
            "Requirement already satisfied: IPython[all] in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 12)) (5.5.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r requirements.txt (line 5)) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r requirements.txt (line 5)) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r requirements.txt (line 5)) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r requirements.txt (line 5)) (2.8.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->-r requirements.txt (line 6)) (2.5)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->-r requirements.txt (line 6)) (1.1.1)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->-r requirements.txt (line 6)) (2.4.1)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0->-r requirements.txt (line 7)) (0.36.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0->-r requirements.txt (line 7)) (1.32.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0->-r requirements.txt (line 7)) (1.1.2)\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0->-r requirements.txt (line 7)) (1.12.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0->-r requirements.txt (line 7)) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0->-r requirements.txt (line 7)) (3.12.4)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 45.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0->-r requirements.txt (line 7)) (0.8.1)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 47.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0->-r requirements.txt (line 7)) (1.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0->-r requirements.txt (line 7)) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0->-r requirements.txt (line 7)) (0.10.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0->-r requirements.txt (line 7)) (0.2.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.1.5->-r requirements.txt (line 8)) (3.13)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.6/dist-packages (from imgaug->-r requirements.txt (line 11)) (1.7.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (4.8.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (0.7.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (2.6.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (4.3.3)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (4.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (51.1.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (1.0.18)\n",
            "Requirement already satisfied: ipykernel; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (4.10.1)\n",
            "Requirement already satisfied: ipywidgets; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (7.6.3)\n",
            "Collecting nose>=0.10.1; extra == \"all\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/d8/dd071918c040f50fa1cf80da16423af51ff8ce4a0f2399b7bf8de45ac3d9/nose-1.3.7-py3-none-any.whl (154kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 53.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: nbformat; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (5.0.8)\n",
            "Requirement already satisfied: Sphinx>=1.3; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (1.8.5)\n",
            "Collecting ipyparallel; extra == \"all\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/e9/03a9189eb39276396309faf28bf833b4328befe4513bbf375b811a36a076/ipyparallel-6.3.0-py3-none-any.whl (199kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 51.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: notebook; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (5.3.1)\n",
            "Requirement already satisfied: qtconsole; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (5.0.1)\n",
            "Requirement already satisfied: requests; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (2.23.0)\n",
            "Requirement already satisfied: testpath; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (0.4.4)\n",
            "Requirement already satisfied: nbconvert; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (5.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0->-r requirements.txt (line 7)) (3.3.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0->-r requirements.txt (line 7)) (1.0.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->IPython[all]->-r requirements.txt (line 12)) (0.7.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->IPython[all]->-r requirements.txt (line 12)) (0.2.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython[all]->-r requirements.txt (line 12)) (0.2.5)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (5.1.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (5.3.5)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (3.5.1)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0; python_version >= \"3.6\" in /usr/local/lib/python3.6/dist-packages (from ipywidgets; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (1.0.0)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (2.6.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbformat; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (4.7.0)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.6/dist-packages (from Sphinx>=1.3; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (2.0.0)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.6/dist-packages (from Sphinx>=1.3; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (0.7.12)\n",
            "Requirement already satisfied: docutils>=0.11 in /usr/local/lib/python3.6/dist-packages (from Sphinx>=1.3; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (0.16)\n",
            "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.6/dist-packages (from Sphinx>=1.3; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (2.9.0)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.6/dist-packages (from Sphinx>=1.3; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (1.2.0)\n",
            "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.6/dist-packages (from Sphinx>=1.3; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (2.11.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from Sphinx>=1.3; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (20.8)\n",
            "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.6/dist-packages (from Sphinx>=1.3; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (1.2.4)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from ipyparallel; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (20.0.0)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.6/dist-packages (from notebook; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (1.5.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from notebook; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (0.9.2)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.6/dist-packages (from qtconsole; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (1.9.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (2.10)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (0.3)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (0.8.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (3.2.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (1.4.3)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (0.6.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0->-r requirements.txt (line 7)) (3.3.0)\n",
            "Requirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.6/dist-packages (from babel!=2.0,>=1.3->Sphinx>=1.3; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (2018.9)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.3->Sphinx>=1.3; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (1.1.1)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml in /usr/local/lib/python3.6/dist-packages (from sphinxcontrib-websupport->Sphinx>=1.3; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (1.1.4)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (0.5.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0->-r requirements.txt (line 7)) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0->-r requirements.txt (line 7)) (3.4.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=41e010ca4a7d1726b3b83ef19d3835eef79c8a0000380a765e5aeefce0135a18\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow 2.4.0 has requirement gast==0.3.3, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.4.0 has requirement tensorboard~=2.4, but you'll have tensorboard 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.4.0 has requirement tensorflow-estimator<2.5.0,>=2.4.0rc0, but you'll have tensorflow-estimator 1.15.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-probability 0.12.1 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: gast, keras-applications, tensorboard, tensorflow-estimator, tensorflow-gpu, keras, nose, ipyparallel\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorboard 2.4.0\n",
            "    Uninstalling tensorboard-2.4.0:\n",
            "      Successfully uninstalled tensorboard-2.4.0\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: Keras 2.4.3\n",
            "    Uninstalling Keras-2.4.3:\n",
            "      Successfully uninstalled Keras-2.4.3\n",
            "Successfully installed gast-0.2.2 ipyparallel-6.3.0 keras-2.1.5 keras-applications-1.0.8 nose-1.3.7 tensorboard-1.15.0 tensorflow-estimator-1.15.1 tensorflow-gpu-1.15.0\n",
            "WARNING:root:Fail load requirements file, so using default ones.\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating mask_rcnn.egg-info\n",
            "writing mask_rcnn.egg-info/PKG-INFO\n",
            "writing dependency_links to mask_rcnn.egg-info/dependency_links.txt\n",
            "writing top-level names to mask_rcnn.egg-info/top_level.txt\n",
            "writing manifest file 'mask_rcnn.egg-info/SOURCES.txt'\n",
            "reading manifest template 'MANIFEST.in'\n",
            "writing manifest file 'mask_rcnn.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib\n",
            "creating build/lib/mrcnn\n",
            "copying mrcnn/config.py -> build/lib/mrcnn\n",
            "copying mrcnn/model.py -> build/lib/mrcnn\n",
            "copying mrcnn/__init__.py -> build/lib/mrcnn\n",
            "copying mrcnn/parallel_model.py -> build/lib/mrcnn\n",
            "copying mrcnn/utils.py -> build/lib/mrcnn\n",
            "copying mrcnn/visualize.py -> build/lib/mrcnn\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/config.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/model.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/__init__.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/parallel_model.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/utils.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/visualize.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/config.py to config.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/model.py to model.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/parallel_model.py to parallel_model.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/utils.py to utils.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/visualize.py to visualize.cpython-36.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying mask_rcnn.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying mask_rcnn.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying mask_rcnn.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying mask_rcnn.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "creating dist\n",
            "creating 'dist/mask_rcnn-2.1-py3.6.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing mask_rcnn-2.1-py3.6.egg\n",
            "Copying mask_rcnn-2.1-py3.6.egg to /usr/local/lib/python3.6/dist-packages\n",
            "Adding mask-rcnn 2.1 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/mask_rcnn-2.1-py3.6.egg\n",
            "Processing dependencies for mask-rcnn==2.1\n",
            "Finished processing dependencies for mask-rcnn==2.1\n",
            "/Done\n",
            "tensorflow version 1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hO_-AIPUwld_",
        "outputId": "212a02dd-8f85-4a6a-c495-17b1a57ca0cc"
      },
      "source": [
        "%cd ~/Mask_RCNN\n",
        "!rm -rf dataset/\n",
        "\n",
        "fileId = \"1S8oMwP6LDfNfZ-JYcwo_sfW7617TtirN\"\n",
        "\n",
        "#https://drive.google.com/file/d/1S8oMwP6LDfNfZ-JYcwo_sfW7617TtirN/view?usp=sharing\n",
        "\n",
        "import os\n",
        "from zipfile import ZipFile\n",
        "from shutil import copy\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "os.makedirs('dataset')\n",
        "os.chdir('dataset')\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "fileName = fileId + '.zip'\n",
        "downloaded = drive.CreateFile({'id': fileId})\n",
        "downloaded.GetContentFile(fileName)\n",
        "ds = ZipFile(fileName)\n",
        "ds.extractall()\n",
        "os.remove(fileName)\n",
        "print('Extracted zip file ' + fileName)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/Mask_RCNN\n",
            "Extracted zip file 1S8oMwP6LDfNfZ-JYcwo_sfW7617TtirN.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9KGaGimw45D",
        "outputId": "12d9fcde-b0b1-4a5f-bdca-0970701720e5"
      },
      "source": [
        "%cd ~/Mask_RCNN\n",
        "!rm -rf dataset/\n",
        "\n",
        "fileId = \"1S8oMwP6LDfNfZ-JYcwo_sfW7617TtirN\"\n",
        "\n",
        "#https://drive.google.com/file/d/1S8oMwP6LDfNfZ-JYcwo_sfW7617TtirN/view?usp=sharing\n",
        "\n",
        "import os\n",
        "from zipfile import ZipFile\n",
        "from shutil import copy\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "os.makedirs('dataset')\n",
        "os.chdir('dataset')\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "fileName = fileId + '.zip'\n",
        "downloaded = drive.CreateFile({'id': fileId})\n",
        "downloaded.GetContentFile(fileName)\n",
        "ds = ZipFile(fileName)\n",
        "ds.extractall()\n",
        "os.remove(fileName)\n",
        "print('Extracted zip file ' + fileName)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/Mask_RCNN\n",
            "Extracted zip file 1S8oMwP6LDfNfZ-JYcwo_sfW7617TtirN.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7K9h_nPw7Rl",
        "outputId": "2ce330d7-76e5-429f-939f-8d0677d4ec12"
      },
      "source": [
        "%cd ~/Mask_RCNN \n",
        "\n",
        "!cp ~/Mask_RCNN/samples/balloon/balloon.py ./facemask.py \n",
        "\n",
        "!sed -i -- 's/balloon/facemask/g' facemask.py\n",
        "!sed -i -- 's/Balloon/Facemask/g' facemask.py\n",
        "!sed -i -- 's/epochs=30/epochs=50/g' facemask.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/Mask_RCNN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7YL_jyBxB9T",
        "outputId": "47d8e40e-5055-4993-a5e5-2382b49cba40"
      },
      "source": [
        "%cd ~/Mask_RCNN\n",
        "\n",
        "!python facemask.py train --dataset=dataset  --weights=coco"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/Mask_RCNN\n",
            "Using TensorFlow backend.\n",
            "Weights:  coco\n",
            "Dataset:  dataset\n",
            "Logs:  /logs\n",
            "\n",
            "Configurations:\n",
            "BACKBONE                       resnet101\n",
            "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
            "BATCH_SIZE                     2\n",
            "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
            "COMPUTE_BACKBONE_SHAPE         None\n",
            "DETECTION_MAX_INSTANCES        100\n",
            "DETECTION_MIN_CONFIDENCE       0.9\n",
            "DETECTION_NMS_THRESHOLD        0.3\n",
            "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
            "GPU_COUNT                      1\n",
            "GRADIENT_CLIP_NORM             5.0\n",
            "IMAGES_PER_GPU                 2\n",
            "IMAGE_CHANNEL_COUNT            3\n",
            "IMAGE_MAX_DIM                  1024\n",
            "IMAGE_META_SIZE                14\n",
            "IMAGE_MIN_DIM                  800\n",
            "IMAGE_MIN_SCALE                0\n",
            "IMAGE_RESIZE_MODE              square\n",
            "IMAGE_SHAPE                    [1024 1024    3]\n",
            "LEARNING_MOMENTUM              0.9\n",
            "LEARNING_RATE                  0.001\n",
            "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
            "MASK_POOL_SIZE                 14\n",
            "MASK_SHAPE                     [28, 28]\n",
            "MAX_GT_INSTANCES               100\n",
            "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
            "MINI_MASK_SHAPE                (56, 56)\n",
            "NAME                           facemask\n",
            "NUM_CLASSES                    2\n",
            "POOL_SIZE                      7\n",
            "POST_NMS_ROIS_INFERENCE        1000\n",
            "POST_NMS_ROIS_TRAINING         2000\n",
            "PRE_NMS_LIMIT                  6000\n",
            "ROI_POSITIVE_RATIO             0.33\n",
            "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
            "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
            "RPN_ANCHOR_STRIDE              1\n",
            "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
            "RPN_NMS_THRESHOLD              0.7\n",
            "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
            "STEPS_PER_EPOCH                100\n",
            "TOP_DOWN_PYRAMID_SIZE          256\n",
            "TRAIN_BN                       False\n",
            "TRAIN_ROIS_PER_IMAGE           200\n",
            "USE_MINI_MASK                  True\n",
            "USE_RPN_ROIS                   True\n",
            "VALIDATION_STEPS               50\n",
            "WEIGHT_DECAY                   0.0001\n",
            "\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:507: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:68: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3831: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3655: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1940: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /root/Mask_RCNN/mrcnn/model.py:553: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n",
            "\n",
            "WARNING:tensorflow:From /root/Mask_RCNN/mrcnn/utils.py:202: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /root/Mask_RCNN/mrcnn/model.py:600: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "Loading weights  /mask_rcnn_coco.h5\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:167: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:179: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2021-01-14 15:48:56.144572: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
            "2021-01-14 15:48:56.149857: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1999995000 Hz\n",
            "2021-01-14 15:48:56.150117: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xa9babc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2021-01-14 15:48:56.150148: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2021-01-14 15:48:56.152458: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2021-01-14 15:48:56.217142: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2021-01-14 15:48:56.217184: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (e8a0c337ec62): /proc/driver/nvidia/version does not exist\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:183: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:192: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "Training network heads\n",
            "\n",
            "Starting at epoch 0. LR=0.001\n",
            "\n",
            "Checkpoint Path: /logs/facemask20210114T1548/mask_rcnn_facemask_{epoch:04d}.h5\n",
            "Selecting layers to train\n",
            "fpn_c5p5               (Conv2D)\n",
            "fpn_c4p4               (Conv2D)\n",
            "fpn_c3p3               (Conv2D)\n",
            "fpn_c2p2               (Conv2D)\n",
            "fpn_p5                 (Conv2D)\n",
            "fpn_p2                 (Conv2D)\n",
            "fpn_p3                 (Conv2D)\n",
            "fpn_p4                 (Conv2D)\n",
            "In model:  rpn_model\n",
            "    rpn_conv_shared        (Conv2D)\n",
            "    rpn_class_raw          (Conv2D)\n",
            "    rpn_bbox_pred          (Conv2D)\n",
            "mrcnn_mask_conv1       (TimeDistributed)\n",
            "mrcnn_mask_bn1         (TimeDistributed)\n",
            "mrcnn_mask_conv2       (TimeDistributed)\n",
            "mrcnn_mask_bn2         (TimeDistributed)\n",
            "mrcnn_class_conv1      (TimeDistributed)\n",
            "mrcnn_class_bn1        (TimeDistributed)\n",
            "mrcnn_mask_conv3       (TimeDistributed)\n",
            "mrcnn_mask_bn3         (TimeDistributed)\n",
            "mrcnn_class_conv2      (TimeDistributed)\n",
            "mrcnn_class_bn2        (TimeDistributed)\n",
            "mrcnn_mask_conv4       (TimeDistributed)\n",
            "mrcnn_mask_bn4         (TimeDistributed)\n",
            "mrcnn_bbox_fc          (TimeDistributed)\n",
            "mrcnn_mask_deconv      (TimeDistributed)\n",
            "mrcnn_class_logits     (TimeDistributed)\n",
            "mrcnn_mask             (TimeDistributed)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:757: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:976: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:963: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:2087: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
            "  UserWarning('Using a generator with `use_multiprocessing=True`'\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:774: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:777: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "Epoch 1/50\n",
            " 99/100 [============================>.] - ETA: 1:11 - loss: 1.4711 - rpn_class_loss: 0.0220 - rpn_bbox_loss: 0.3825 - mrcnn_class_loss: 0.0844 - mrcnn_bbox_loss: 0.4797 - mrcnn_mask_loss: 0.5025/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:2330: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
            "  UserWarning('Using a generator with `use_multiprocessing=True`'\n",
            "100/100 [==============================] - 8181s 82s/step - loss: 1.4648 - rpn_class_loss: 0.0218 - rpn_bbox_loss: 0.3799 - mrcnn_class_loss: 0.0839 - mrcnn_bbox_loss: 0.4798 - mrcnn_mask_loss: 0.4994 - val_loss: 0.9554 - val_rpn_class_loss: 0.0136 - val_rpn_bbox_loss: 0.2746 - val_mrcnn_class_loss: 0.0367 - val_mrcnn_bbox_loss: 0.3910 - val_mrcnn_mask_loss: 0.2394\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:860: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
            "\n",
            "Epoch 2/50\n",
            "100/100 [==============================] - 8057s 81s/step - loss: 0.5458 - rpn_class_loss: 0.0100 - rpn_bbox_loss: 0.1295 - mrcnn_class_loss: 0.0254 - mrcnn_bbox_loss: 0.2106 - mrcnn_mask_loss: 0.1702 - val_loss: 0.7390 - val_rpn_class_loss: 0.0095 - val_rpn_bbox_loss: 0.2350 - val_mrcnn_class_loss: 0.0282 - val_mrcnn_bbox_loss: 0.2870 - val_mrcnn_mask_loss: 0.1793\n",
            "Epoch 3/50\n",
            "100/100 [==============================] - 8137s 81s/step - loss: 0.3294 - rpn_class_loss: 0.0065 - rpn_bbox_loss: 0.0722 - mrcnn_class_loss: 0.0161 - mrcnn_bbox_loss: 0.1110 - mrcnn_mask_loss: 0.1236 - val_loss: 0.6270 - val_rpn_class_loss: 0.0072 - val_rpn_bbox_loss: 0.1958 - val_mrcnn_class_loss: 0.0258 - val_mrcnn_bbox_loss: 0.2232 - val_mrcnn_mask_loss: 0.1749\n",
            "Epoch 4/50\n",
            " 30/100 [========>.....................] - ETA: 1:22:51 - loss: 0.2518 - rpn_class_loss: 0.0050 - rpn_bbox_loss: 0.0604 - mrcnn_class_loss: 0.0134 - mrcnn_bbox_loss: 0.0675 - mrcnn_mask_loss: 0.1056"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26MljRxvxbtr"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir \"/logs\"\n",
        "print(\"C'est fait\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYrS2Ih6xeAi"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import sys\n",
        "import random\n",
        "import math\n",
        "import re\n",
        "import time\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import skimage\n",
        "import glob\n",
        "from mrcnn import utils\n",
        "from mrcnn import visualize\n",
        "from mrcnn.visualize import display_images\n",
        "import mrcnn.model as modellib\n",
        "from mrcnn.model import log\n",
        "\n",
        "import casque\n",
        "\n",
        "# Root directory of the project\n",
        "ROOT_DIR = os.getcwd()\n",
        "\n",
        "# Import Mask RCNN\n",
        "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
        "\n",
        "custom_WEIGHTS_PATH = sorted(glob.glob(\"/logs/*/mask_rcnn_*.h5\"))[-1]\n",
        "\n",
        "%matplotlib inline \n",
        "\n",
        "# Directory to save logs and trained model\n",
        "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
        "\n",
        "config = casque.CasqueConfig()\n",
        "custom_DIR = os.path.join(ROOT_DIR, \"dataset\")\n",
        "\n",
        "class InferenceConfig(config.__class__):\n",
        "  GPU_COUNT = 1\n",
        "  IMAGES_PER_GPU = 1\n",
        "\n",
        "config = InferenceConfig()\n",
        "config.display()\n",
        "\n",
        "# Device to load the neural network on.\n",
        "# Useful if you're training a model on the same \n",
        "# machine, in which case use CPU and leave the\n",
        "# GPU for training.\n",
        "DEVICE = \"/gpu:0\"  # /cpu:0 or /gpu:0\n",
        "\n",
        "# Inspect the model in training or inference modes\n",
        "# values: 'inference' or 'training'\n",
        "# TODO: code for 'training' test mode not ready yet\n",
        "TEST_MODE = \"inference\"\n",
        "\n",
        "def get_ax(rows=1, cols=1, size=16):\n",
        "    \"\"\"Return a Matplotlib Axes array to be used in\n",
        "    all visualizations in the notebook. Provide a\n",
        "    central point to control graph sizes.\n",
        "    \n",
        "    Adjust the size attribute to control how big to render images\n",
        "    \"\"\"\n",
        "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
        "    return ax\n",
        "  \n",
        "# Load validation dataset\n",
        "dataset = casque.CasqueDataset()\n",
        "dataset.load_casque(custom_DIR, \"val\")\n",
        "\n",
        "# Must call before using the dataset\n",
        "dataset.prepare()\n",
        "\n",
        "print(\"Images: {}\\nClasses: {}\".format(len(dataset.image_ids), dataset.class_names))\n",
        "\n",
        "# Create model in inference mode\n",
        "with tf.device(DEVICE):\n",
        "    model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR,\n",
        "                              config=config)\n",
        "# Load weights\n",
        "print(\"Loading weights \", custom_WEIGHTS_PATH)\n",
        "model.load_weights(custom_WEIGHTS_PATH, by_name=True)\n",
        "\n",
        "from importlib import reload # was constantly changin the visualization, so I decided to reload it instead of notebook\n",
        "reload(visualize)\n",
        "print(\"C'est fait\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7Zwb1f8xgPG"
      },
      "source": [
        "#image_id = random.choice(dataset.image_ids)\n",
        "for image_id in dataset.image_ids:\n",
        "  image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "      modellib.load_image_gt(dataset, config, image_id, use_mini_mask=False)\n",
        "  info = dataset.image_info[image_id]\n",
        "  print(\"image ID: {}.{} ({}) {}\".format(info[\"source\"], info[\"id\"], image_id, \n",
        "                                         dataset.image_reference(image_id)))\n",
        "\n",
        "  # Run object detection\n",
        "  results = model.detect([image], verbose=1)\n",
        "\n",
        "  # Display results\n",
        "  ax = get_ax(1)\n",
        "  r = results[0]\n",
        "  visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], \n",
        "                              dataset.class_names, r['scores'], ax=ax,\n",
        "                              title=\"Predictions\")\n",
        "  log(\"gt_class_id\", gt_class_id)\n",
        "  log(\"gt_bbox\", gt_bbox)\n",
        "  log(\"gt_mask\", gt_mask)\n",
        "print(\"C'est fait\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmkT-tNfxiD3"
      },
      "source": [
        "# This is for predicting images which are not present in dataset\n",
        "#image_id = random.choice(dataset.image_ids)\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "image1 = mpimg.imread('/root/Mask_RCNN/dataset/val/000.jpeg')\n",
        "\n",
        "    # Run object detection\n",
        "\n",
        "print(len([image1]))\n",
        "results1 = model.detect([image1], verbose=1)\n",
        "\n",
        "    # Display results\n",
        "ax = get_ax(1)\n",
        "r1 = results1[0]\n",
        "visualize.display_instances(image1, r1['rois'], r1['masks'], r1['class_ids'],\n",
        "                            dataset.class_names, r1['scores'], ax=ax,\n",
        "                            title=\"Predictions1\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}